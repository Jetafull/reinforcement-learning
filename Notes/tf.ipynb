{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes for DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to populate replay memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivoting based on dimension in numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(state_next[:, :, None] == np.expand_dims(state_next, axis=2)).all() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each step, we generate one image. Each state is a sequence of 4 images (4 x 84 x 84, treat it like an image with 4 channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "states = np.stack([np.random.randint(0, 255, [84, 84])] * 4, axis=2)\n",
    "state_next = np.random.randint(0, 255, [84, 84])\n",
    "new_states = np.append(states[:, :, 1:], np.expand_dims(state_next, 2), axis=2)\n",
    "print((new_states[0, :, 3] == state_next[0, :]).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to calculate loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To get loss, from each transition (state, action, reward, next_state), we use\n",
    "1. state |[$\\epsilon-greedy$]=> action |[env.step]=> transition (state, action, reward, next_state)\n",
    "2. transition |=> q_values_next |[$greedy$]=> target\n",
    "3. state, action |=> q_value for action\n",
    "4. $loss = \\frac{1}{2}(target - q\\_value)^2$\n",
    "\n",
    "The chosen action plays two roles: it generates the next state and the corresponding q_value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick up action predictions (values) for only selected actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions batch_size X num_actions\n",
      "[[0.08078424 0.76907652 0.57850815 0.98225583]\n",
      " [0.99025714 0.32141543 0.60348217 0.7804746 ]\n",
      " [0.11778576 0.84922858 0.92765091 0.61298925]\n",
      " [0.30463415 0.50167728 0.59557644 0.12356276]\n",
      " [0.07895121 0.10563141 0.02999877 0.13290146]\n",
      " [0.72537502 0.56490885 0.75581052 0.68317478]\n",
      " [0.19152837 0.4128727  0.9772954  0.62705295]\n",
      " [0.37081678 0.23505685 0.26570782 0.13261947]\n",
      " [0.54624099 0.90158146 0.74054228 0.75706725]\n",
      " [0.93635203 0.51483494 0.8761039  0.59076226]]\n",
      "gather_indices: [ 3  4 10 14 19 22 26 28 33 36]\n",
      "action_predictions: [0.98225583 0.99025714 0.92765091 0.59557644 0.13290146 0.75581052\n",
      " 0.9772954  0.37081678 0.90158146 0.93635203]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "action_space = [0, 1, 2, 3] \n",
    "n_actions = len(action_space)\n",
    "\n",
    "# predictions (q-values) from q-estimator for each obs\n",
    "predictions = np.random.uniform(size=(batch_size, n_actions))\n",
    "print('predictions batch_size X num_actions')\n",
    "print(predictions)\n",
    "\n",
    "# chosen actions (from epsilon-greedy) for each obs\n",
    "actions_pl = [np.argmax(pred) for pred in predictions]\n",
    "\n",
    "gather_indices = tf.range(batch_size) * tf.shape(predictions)[1] + actions_pl\n",
    "print('gather_indices: {}'.format(gather_indices))\n",
    "# get q-value for chosen action for each obs\n",
    "action_predictions = tf.gather(tf.reshape(predictions, [-1]), gather_indices)\n",
    "print('action_predictions: {}'.format(action_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `np.invert` for negate when batch is done\n",
    "```python\n",
    "targets = reward_batch + np.invert(done_batch).astype(np.float).discount_factor * np.max(value_next_state_batch, axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.invert(np.array([True, False])).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
